{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['description'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70e1fdac6462>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'fraudulent'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tweet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fraudulent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fraudulent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'real'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['description'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "# # #print(df.head())\n",
    "\n",
    "\n",
    "# df = df[['description', 'fraudulent']]\n",
    "# print(df.head())\n",
    "\n",
    "df = pd.read_csv(\"all.tsv\", delimiter='\\t')\n",
    "\n",
    "df.rename(columns={'label':'fraudulent', 'tweet':'description'}, inplace=True)\n",
    "df = df[['description', 'fraudulent']]\n",
    "for i in range(len(df)):\n",
    "    if(df.at[i,'fraudulent'] == 'real'):\n",
    "        df.at[i,'fraudulent'] = 0\n",
    "    else:\n",
    "        df.at[i,'fraudulent'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(df['fraudulent'].values))\n",
    "\n",
    "df_fraudulent= df[df['fraudulent'] == 1] \n",
    "df_normal = df[df['fraudulent'] == 0] \n",
    "df_normal = df_normal.sample(n=len(df_fraudulent))\n",
    "df = df_normal.append(df_fraudulent)\n",
    "df = df.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
    "\n",
    "print(Counter(df['fraudulent'].values))\n",
    "\n",
    "\n",
    "train_data = df.head(10)\n",
    "print(train_data)\n",
    "test_data = df.tail(10)\n",
    "print(test_data)\n",
    "\n",
    "train_data = [{'description': description, 'fraudulent': fraudulent } for description in list(train_data['description']) for fraudulent in list(train_data['fraudulent'])]\n",
    "test_data = [{'description': description, 'fraudulent': fraudulent } for description in list(test_data['description']) for fraudulent in list(test_data['fraudulent'])]\n",
    "\n",
    "train_texts, train_labels = list(zip(*map(lambda d: (d['description'], d['fraudulent']), train_data)))\n",
    "test_texts, test_labels = list(zip(*map(lambda d: (d['description'], d['fraudulent']), test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our daily update is published. Weâ€™ve now tracked 5.4 million tests up 257k from yesterday. Another huge testing day. 4/22 was a clear inflection point. Note that we can only track tests that a state reports. For details see: https://t.co/PZrmH4bl5Y https://t.co/2PuyjEbdyA\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:199], train_texts))\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:199], test_texts))\n",
    "train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=200, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=200, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "\n",
    "train_y = np.array(train_labels) == 1\n",
    "test_y = np.array(test_labels) == 1\n",
    "\n",
    "\n",
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "train_masks_tensor = torch.tensor(train_masks)\n",
    "test_masks_tensor = torch.tensor(test_masks)\n",
    "\n",
    "train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "0/100.0 loss: 0.8984752893447876 \n",
      "Epoch:  1\n",
      "1/100.0 loss: 0.7197897136211395 \n",
      "Epoch:  1\n",
      "2/100.0 loss: 0.6767944494883219 \n",
      "Epoch:  1\n",
      "3/100.0 loss: 0.6325837001204491 \n",
      "Epoch:  1\n",
      "4/100.0 loss: 0.6079475462436676 \n",
      "Epoch:  1\n",
      "5/100.0 loss: 0.6056357771158218 \n",
      "Epoch:  1\n",
      "6/100.0 loss: 0.5756295280797141 \n",
      "Epoch:  1\n",
      "7/100.0 loss: 0.6322903521358967 \n",
      "Epoch:  1\n",
      "8/100.0 loss: 0.6649254328674741 \n",
      "Epoch:  1\n",
      "9/100.0 loss: 0.6496612280607224 \n",
      "Epoch:  1\n",
      "10/100.0 loss: 0.6337287371808832 \n",
      "Epoch:  1\n",
      "11/100.0 loss: 0.6145353019237518 \n",
      "Epoch:  1\n",
      "12/100.0 loss: 0.5952109946654394 \n",
      "Epoch:  1\n",
      "13/100.0 loss: 0.5860455334186554 \n",
      "Epoch:  1\n",
      "14/100.0 loss: 0.5821415026982625 \n",
      "Epoch:  1\n",
      "15/100.0 loss: 0.5712498743087053 \n",
      "Epoch:  1\n",
      "16/100.0 loss: 0.562231274212108 \n",
      "Epoch:  1\n",
      "17/100.0 loss: 0.5584121147791544 \n",
      "Epoch:  1\n",
      "18/100.0 loss: 0.5471213444283134 \n",
      "Epoch:  1\n",
      "19/100.0 loss: 0.5771749094128609 \n",
      "Epoch:  1\n",
      "20/100.0 loss: 0.5668790553297315 \n",
      "Epoch:  1\n",
      "21/100.0 loss: 0.5570424984801899 \n",
      "Epoch:  1\n",
      "22/100.0 loss: 0.5503702474677045 \n",
      "Epoch:  1\n",
      "23/100.0 loss: 0.546064638843139 \n",
      "Epoch:  1\n",
      "24/100.0 loss: 0.5415812504291534 \n",
      "Epoch:  1\n",
      "25/100.0 loss: 0.5579346085970218 \n",
      "Epoch:  1\n",
      "26/100.0 loss: 0.5527419889414752 \n",
      "Epoch:  1\n",
      "27/100.0 loss: 0.5478066386921066 \n",
      "Epoch:  1\n",
      "28/100.0 loss: 0.5425320915107069 \n",
      "Epoch:  1\n",
      "29/100.0 loss: 0.5618246167898178 \n",
      "Epoch:  1\n",
      "30/100.0 loss: 0.5793535565176318 \n",
      "Epoch:  1\n",
      "31/100.0 loss: 0.5987217323854566 \n",
      "Epoch:  1\n",
      "32/100.0 loss: 0.6205169549494078 \n",
      "Epoch:  1\n",
      "33/100.0 loss: 0.6128598495441324 \n",
      "Epoch:  1\n",
      "34/100.0 loss: 0.6072720246655601 \n",
      "Epoch:  1\n",
      "35/100.0 loss: 0.6011138127909766 \n",
      "Epoch:  1\n",
      "36/100.0 loss: 0.6142640049393112 \n",
      "Epoch:  1\n",
      "37/100.0 loss: 0.6094231503574472 \n",
      "Epoch:  1\n",
      "38/100.0 loss: 0.6033578836000882 \n",
      "Epoch:  1\n",
      "39/100.0 loss: 0.5988496862351894 \n",
      "Epoch:  1\n",
      "40/100.0 loss: 0.5935630463972325 \n",
      "Epoch:  1\n",
      "41/100.0 loss: 0.5896769201471692 \n",
      "Epoch:  1\n",
      "42/100.0 loss: 0.5855974333230839 \n",
      "Epoch:  1\n",
      "43/100.0 loss: 0.6000423932617361 \n",
      "Epoch:  1\n",
      "44/100.0 loss: 0.5961892247200012 \n",
      "Epoch:  1\n",
      "45/100.0 loss: 0.6044979600802712 \n",
      "Epoch:  1\n",
      "46/100.0 loss: 0.6005358543801815 \n",
      "Epoch:  1\n",
      "47/100.0 loss: 0.6115538080533346 \n",
      "Epoch:  1\n",
      "48/100.0 loss: 0.6081850388828589 \n",
      "Epoch:  1\n",
      "49/100.0 loss: 0.6194192081689834 \n",
      "Epoch:  1\n",
      "50/100.0 loss: 0.6150068225813847 \n",
      "Epoch:  1\n",
      "51/100.0 loss: 0.6125853875508676 \n",
      "Epoch:  1\n",
      "52/100.0 loss: 0.6218896058370482 \n",
      "Epoch:  1\n",
      "53/100.0 loss: 0.6194922339033198 \n",
      "Epoch:  1\n",
      "54/100.0 loss: 0.6151011499491605 \n",
      "Epoch:  1\n",
      "55/100.0 loss: 0.6253875802670207 \n",
      "Epoch:  1\n",
      "56/100.0 loss: 0.6207455668533057 \n",
      "Epoch:  1\n",
      "57/100.0 loss: 0.6295032295687445 \n",
      "Epoch:  1\n",
      "58/100.0 loss: 0.6250600269285299 \n",
      "Epoch:  1\n",
      "59/100.0 loss: 0.6338040749231975 \n",
      "Epoch:  1\n",
      "60/100.0 loss: 0.6297521273620793 \n",
      "Epoch:  1\n",
      "61/100.0 loss: 0.6259300843361886 \n",
      "Epoch:  1\n",
      "62/100.0 loss: 0.6216568246720329 \n",
      "Epoch:  1\n",
      "63/100.0 loss: 0.6310529001057148 \n",
      "Epoch:  1\n",
      "64/100.0 loss: 0.6266614776391249 \n",
      "Epoch:  1\n",
      "65/100.0 loss: 0.6231890528491049 \n",
      "Epoch:  1\n",
      "66/100.0 loss: 0.6200673273250238 \n",
      "Epoch:  1\n",
      "67/100.0 loss: 0.6168642293880967 \n",
      "Epoch:  1\n",
      "68/100.0 loss: 0.6137338980384495 \n",
      "Epoch:  1\n",
      "69/100.0 loss: 0.611050027183124 \n",
      "Epoch:  1\n",
      "70/100.0 loss: 0.6081026498700531 \n",
      "Epoch:  1\n",
      "71/100.0 loss: 0.6143143698573112 \n",
      "Epoch:  1\n",
      "72/100.0 loss: 0.6120788826517862 \n",
      "Epoch:  1\n",
      "73/100.0 loss: 0.6085953104334909 \n",
      "Epoch:  1\n",
      "74/100.0 loss: 0.6133172778288524 \n",
      "Epoch:  1\n",
      "75/100.0 loss: 0.6104930549075729 \n",
      "Epoch:  1\n",
      "76/100.0 loss: 0.6069435055379744 \n",
      "Epoch:  1\n",
      "77/100.0 loss: 0.603760241315915 \n",
      "Epoch:  1\n",
      "78/100.0 loss: 0.611452226774602 \n",
      "Epoch:  1\n",
      "79/100.0 loss: 0.6172380451112985 \n",
      "Epoch:  1\n",
      "80/100.0 loss: 0.6147361066606309 \n",
      "Epoch:  1\n",
      "81/100.0 loss: 0.6112049483671421 \n",
      "Epoch:  1\n",
      "82/100.0 loss: 0.6080603613910904 \n",
      "Epoch:  1\n",
      "83/100.0 loss: 0.6056274218218667 \n",
      "Epoch:  1\n",
      "84/100.0 loss: 0.6028955256237704 \n",
      "Epoch:  1\n",
      "85/100.0 loss: 0.6003329750410346 \n",
      "Epoch:  1\n",
      "86/100.0 loss: 0.5982778514253682 \n",
      "Epoch:  1\n",
      "87/100.0 loss: 0.6068296706811949 \n",
      "Epoch:  1\n",
      "88/100.0 loss: 0.6048047961143965 \n",
      "Epoch:  1\n",
      "89/100.0 loss: 0.6015737238857481 \n",
      "Epoch:  1\n",
      "90/100.0 loss: 0.5991471986194233 \n",
      "Epoch:  1\n",
      "91/100.0 loss: 0.6063048444364382 \n",
      "Epoch:  1\n",
      "92/100.0 loss: 0.611130480484296 \n",
      "Epoch:  1\n",
      "93/100.0 loss: 0.6176357415128262 \n",
      "Epoch:  1\n",
      "94/100.0 loss: 0.6145122088884053 \n",
      "Epoch:  1\n",
      "95/100.0 loss: 0.6221880974868933 \n",
      "Epoch:  1\n",
      "96/100.0 loss: 0.6191229092091629 \n",
      "Epoch:  1\n",
      "97/100.0 loss: 0.6264832819602928 \n",
      "Epoch:  1\n",
      "98/100.0 loss: 0.6335279348522725 \n",
      "Epoch:  1\n",
      "99/100.0 loss: 0.6309538498520851 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.40      1.00      0.57        40\n",
      "        True       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.40       100\n",
      "   macro avg       0.20      0.50      0.29       100\n",
      "weighted avg       0.16      0.40      0.23       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navyasree\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Navyasree\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Navyasree\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "bert_clf = BertBinaryClassifier()\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bert_clf.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "        probas = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "        bert_clf.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
    "        \n",
    "bert_clf.eval()\n",
    "bert_predicted = []\n",
    "all_logits = []\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(test_dataloader):\n",
    "\n",
    "        token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "\n",
    "        logits = bert_clf(token_ids, masks)\n",
    "        loss_func = nn.BCELoss()\n",
    "        loss = loss_func(logits, labels)\n",
    "        numpy_logits = logits.cpu().detach().numpy()\n",
    "        \n",
    "        bert_predicted += list(numpy_logits[:, 0] > 0.5)\n",
    "        all_logits += list(numpy_logits[:, 0])\n",
    "        \n",
    "print(classification_report(test_y, bert_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertBinaryClassifier' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-734a0f7dace2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbert_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\FakeNews\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    946\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 948\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertBinaryClassifier' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "bert_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
